{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49d23dea",
   "metadata": {},
   "source": [
    "# notes\n",
    "\n",
    "#### - Before using the YOLOV8 model you should install the ultralytics library\n",
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe19374",
   "metadata": {},
   "source": [
    "# Testing  the model on a webcame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a85171b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x480 (no detections), 132.6ms\n",
      "Speed: 5.0ms preprocess, 132.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 133.0ms\n",
      "Speed: 4.0ms preprocess, 133.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 134.1ms\n",
      "Speed: 5.0ms preprocess, 134.1ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 133.0ms\n",
      "Speed: 4.0ms preprocess, 133.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.4ms\n",
      "Speed: 4.0ms preprocess, 129.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 5.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 133.0ms\n",
      "Speed: 4.0ms preprocess, 133.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 135.0ms\n",
      "Speed: 4.0ms preprocess, 135.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 5.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 133.0ms\n",
      "Speed: 8.0ms preprocess, 133.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 133.0ms\n",
      "Speed: 4.0ms preprocess, 133.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.5ms\n",
      "Speed: 5.0ms preprocess, 131.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 128.0ms\n",
      "Speed: 3.0ms preprocess, 128.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 128.0ms\n",
      "Speed: 3.0ms preprocess, 128.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.5ms\n",
      "Speed: 2.0ms preprocess, 130.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 128.0ms\n",
      "Speed: 4.0ms preprocess, 128.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 3.0ms preprocess, 130.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.5ms\n",
      "Speed: 3.0ms preprocess, 131.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 133.0ms\n",
      "Speed: 4.0ms preprocess, 133.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 133.0ms\n",
      "Speed: 4.0ms preprocess, 133.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 3.0ms preprocess, 130.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 5.0ms preprocess, 131.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.5ms\n",
      "Speed: 3.0ms preprocess, 131.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.5ms\n",
      "Speed: 4.0ms preprocess, 130.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 3.0ms preprocess, 130.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 2.0ms preprocess, 131.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 2.0ms preprocess, 131.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 2.0ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 3.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 2.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 128.0ms\n",
      "Speed: 3.0ms preprocess, 128.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 2.0ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 2.0ms preprocess, 131.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 2.0ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 128.0ms\n",
      "Speed: 3.0ms preprocess, 128.0ms inference, 35.8ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 130.0ms\n",
      "Speed: 3.0ms preprocess, 130.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.1ms\n",
      "Speed: 4.0ms preprocess, 130.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 2 h_ls, 130.0ms\n",
      "Speed: 3.0ms preprocess, 130.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 128.6ms\n",
      "Speed: 4.0ms preprocess, 128.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.4ms\n",
      "Speed: 3.0ms preprocess, 129.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 128.0ms\n",
      "Speed: 4.0ms preprocess, 128.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 2.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 2.0ms preprocess, 131.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 2.0ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.5ms\n",
      "Speed: 4.0ms preprocess, 130.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 136.0ms\n",
      "Speed: 3.0ms preprocess, 136.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 5.0ms preprocess, 129.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 128.0ms\n",
      "Speed: 5.0ms preprocess, 128.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO('../model_versions/bestV2.pt')\n",
    "\n",
    "# Capture video from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "    # Run YOLOv8 inference\n",
    "    results = model(frame)\n",
    "    boxes = results[0].boxes.cpu().numpy()\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    cv2.imshow('YOLOv8 Inference', results[0].plot())\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa968cbd",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "### Obersvation\n",
    "The initail tests of the model with webcome showed that the model is not effective at detecting the h_l and the logo parts when they are inversed because the model trained only on the normal position of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517fda46",
   "metadata": {},
   "source": [
    "# Testing the model on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03ba33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Ahmed\\Desktop\\New folder (5)\\top_tether_ai_detection\\test_code\\..\\test_images\\normal.jpg: 608x800 1 h_l, 1 logo, 1 text, 255.1ms\n",
      "Speed: 10.0ms preprocess, 255.1ms inference, 11.0ms postprocess per image at shape (1, 3, 608, 800)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box coordinates: 2749.533935546875, 1770.974365234375, 3128.330322265625, 2054.586669921875, Confidence: 0.9279471635818481, Class ID: 1.0\n",
      "Box coordinates: 2750.958984375, 2081.702392578125, 3130.80712890625, 2309.92724609375, Confidence: 0.9226164817810059, Class ID: 2.0\n",
      "Box coordinates: 1572.9898681640625, 1821.4395751953125, 2595.52978515625, 1961.6376953125, Confidence: 0.7897914052009583, Class ID: 0.0\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO('../model_versions/bestV1.pt')\n",
    "results = model('../test_images/normal.jpg')\n",
    "for det in results[0].boxes:\n",
    "    xmin, ymin, xmax, ymax = det.xyxy[0].tolist()  # Convert tensor to list for easier handling\n",
    "    conf = det.conf.item()  # Get Python number from tensor\n",
    "    cls = det.cls.item()# Get Python number from tensor\n",
    "   \n",
    "    print(f\"Box coordinates: {xmin}, {ymin}, {xmax}, {ymax}, Confidence: {conf}, Class ID: {cls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5911f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'h_l', 1: 'logo', 2: 'text'}\n",
      "orig_img: array([[[246, 248, 248],\n",
      "        [248, 250, 250],\n",
      "        [248, 250, 250],\n",
      "        ...,\n",
      "        [233, 235, 236],\n",
      "        [231, 233, 234],\n",
      "        [232, 234, 235]],\n",
      "\n",
      "       [[246, 248, 248],\n",
      "        [247, 249, 249],\n",
      "        [248, 250, 250],\n",
      "        ...,\n",
      "        [231, 233, 234],\n",
      "        [229, 231, 232],\n",
      "        [230, 232, 233]],\n",
      "\n",
      "       [[246, 248, 248],\n",
      "        [246, 248, 248],\n",
      "        [247, 249, 249],\n",
      "        ...,\n",
      "        [229, 231, 232],\n",
      "        [227, 229, 230],\n",
      "        [228, 230, 231]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[250, 255, 255],\n",
      "        [250, 255, 255],\n",
      "        [250, 255, 255],\n",
      "        ...,\n",
      "        [121, 144, 170],\n",
      "        [120, 143, 169],\n",
      "        [120, 143, 169]],\n",
      "\n",
      "       [[251, 255, 255],\n",
      "        [251, 255, 255],\n",
      "        [251, 255, 255],\n",
      "        ...,\n",
      "        [115, 136, 163],\n",
      "        [114, 135, 162],\n",
      "        [114, 135, 162]],\n",
      "\n",
      "       [[251, 255, 255],\n",
      "        [251, 255, 255],\n",
      "        [251, 255, 255],\n",
      "        ...,\n",
      "        [114, 135, 162],\n",
      "        [114, 135, 162],\n",
      "        [114, 135, 162]]], dtype=uint8)\n",
      "orig_shape: (3096, 4128)\n",
      "path: 'C:\\\\Users\\\\Ahmed\\\\Desktop\\\\New folder (5)\\\\top_tether_ai_detection\\\\test_code\\\\..\\\\test_images\\\\normal.jpg'\n",
      "probs: None\n",
      "save_dir: None\n",
      "speed: {'preprocess': 10.00070571899414, 'inference': 255.07020950317383, 'postprocess': 11.003494262695312}\n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b22047",
   "metadata": {},
   "source": [
    "# Solving the logo problmes  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353e5c9e",
   "metadata": {},
   "source": [
    "### 1- identifying the positions of the bounding boxes in the normal correct piece\n",
    "<img src=\"../test_images/normal.jpg\" style=\"height:300px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7acb2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x480 (no detections), 133.0ms\n",
      "Speed: 6.0ms preprocess, 133.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.4ms\n",
      "Speed: 5.0ms preprocess, 131.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values are not available\n",
      "Values are not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 133.0ms\n",
      "Speed: 5.0ms preprocess, 133.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values are not available\n",
      "Values are not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 5.0ms preprocess, 132.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 logo, 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values are not available\n",
      "Values are not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 logo, 133.0ms\n",
      "Speed: 4.0ms preprocess, 133.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 131.0ms\n",
      "Speed: 5.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values are not available\n",
      "Values are not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 5.0ms preprocess, 132.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 5.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values are not available\n",
      "Values are not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 (no detections), 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 129.1ms\n",
      "Speed: 4.0ms preprocess, 129.1ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values are not available\n",
      "Values are not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 (no detections), 128.6ms\n",
      "Speed: 4.0ms preprocess, 128.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 (no detections), 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values are not available\n",
      "Values are not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 logo, 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 5.0ms preprocess, 132.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values are not available\n",
      "165.29434204101562\n",
      "161.693603515625\n",
      "1.0222688989984856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164.23568725585938\n",
      "158.2669677734375\n",
      "1.0377129831094396\n",
      "164.82423400878906\n",
      "160.8509063720703\n",
      "1.0247019288006243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 5.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169.8914794921875\n",
      "163.89596557617188\n",
      "1.0365812172065283\n",
      "174.87210083007812\n",
      "169.24539184570312\n",
      "1.0332458622536957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 2 texts, 130.6ms\n",
      "Speed: 5.0ms preprocess, 130.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.01937866210938\n",
      "171.911376953125\n",
      "1.0297129939828076\n",
      "180.00448608398438\n",
      "175.03009033203125\n",
      "1.0284202318727982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 2 texts, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 2 texts, 130.0ms\n",
      "Speed: 5.0ms preprocess, 130.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.08326721191406\n",
      "175.8040313720703\n",
      "1.035717246020112\n",
      "183.3015594482422\n",
      "177.3264617919922\n",
      "1.033695465391166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 128.0ms\n",
      "Speed: 5.0ms preprocess, 128.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 5.0ms preprocess, 132.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.96249389648438\n",
      "178.46035766601562\n",
      "1.0252276544177636\n",
      "182.6880645751953\n",
      "178.14161682128906\n",
      "1.0255215363766863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 3.9ms preprocess, 132.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184.70309448242188\n",
      "179.44854736328125\n",
      "1.0292816364152737\n",
      "183.17398071289062\n",
      "179.13333129882812\n",
      "1.0225566586897328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 5.0ms preprocess, 130.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.4125213623047\n",
      "179.2032012939453\n",
      "1.0346496046026226\n",
      "182.04510498046875\n",
      "178.59320068359375\n",
      "1.0193283074812607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 129.0ms\n",
      "Speed: 5.0ms preprocess, 129.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184.83145141601562\n",
      "180.228271484375\n",
      "1.0255408316005499\n",
      "188.1495819091797\n",
      "182.68922424316406\n",
      "1.0298887779979171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.7769775390625\n",
      "188.86968994140625\n",
      "1.0259823987595822\n",
      "207.5266876220703\n",
      "201.74317932128906\n",
      "1.0286676769952685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 133.0ms\n",
      "Speed: 3.0ms preprocess, 133.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 2 texts, 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216.11669921875\n",
      "209.43203735351562\n",
      "1.0319180482112718\n",
      "222.7262725830078\n",
      "216.7944793701172\n",
      "1.0273613665353707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 5.0ms preprocess, 130.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228.6588897705078\n",
      "221.96205139160156\n",
      "1.030171096081155\n",
      "229.48329162597656\n",
      "223.02394104003906\n",
      "1.0289625883024722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 2 texts, 131.0ms\n",
      "Speed: 5.0ms preprocess, 131.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 2 texts, 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224.4408721923828\n",
      "218.2204132080078\n",
      "1.0285053945821543\n",
      "218.92962646484375\n",
      "213.23153686523438\n",
      "1.026722546220781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213.64361572265625\n",
      "207.89962768554688\n",
      "1.0276286595654576\n",
      "207.810791015625\n",
      "201.6439208984375\n",
      "1.0305829706628924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 129.0ms\n",
      "Speed: 5.0ms preprocess, 129.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198.836181640625\n",
      "192.55819702148438\n",
      "1.0326030504868102\n",
      "190.63583374023438\n",
      "185.72836303710938\n",
      "1.0264228393707668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 5.0ms preprocess, 132.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188.53677368164062\n",
      "183.14584350585938\n",
      "1.0294351762103122\n",
      "182.0497589111328\n",
      "176.1319122314453\n",
      "1.033598946407345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176.1865692138672\n",
      "170.4142608642578\n",
      "1.0338722142169032\n",
      "170.6458740234375\n",
      "165.52163696289062\n",
      "1.0309581100970848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169.0250244140625\n",
      "163.87701416015625\n",
      "1.0314138641119928\n",
      "165.23089599609375\n",
      "160.92333984375\n",
      "1.0267677526238657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.871826171875\n",
      "152.61209106445312\n",
      "1.0279121731293417\n",
      "155.62069702148438\n",
      "152.631103515625\n",
      "1.0195870529466056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 3.0ms preprocess, 130.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 2 texts, 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156.78195190429688\n",
      "153.2601318359375\n",
      "1.0229793621222343\n",
      "167.25064086914062\n",
      "162.5655517578125\n",
      "1.0288196918760986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173.6537628173828\n",
      "168.6604461669922\n",
      "1.0296057360446367\n",
      "179.9665069580078\n",
      "174.6665496826172\n",
      "1.0303432871664384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 5.0ms preprocess, 131.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.3972625732422\n",
      "180.4765167236328\n",
      "1.0272652971086793\n",
      "189.509033203125\n",
      "185.04623413085938\n",
      "1.0241172109944678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206.4332275390625\n",
      "200.03463745117188\n",
      "1.0319874106275846\n",
      "217.11170959472656\n",
      "210.87550354003906\n",
      "1.0295729278650112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 4.0ms preprocess, 132.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222.33053588867188\n",
      "217.6116943359375\n",
      "1.0216846873378491\n",
      "228.1715087890625\n",
      "222.08001708984375\n",
      "1.0274292652668269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234.21563720703125\n",
      "227.52593994140625\n",
      "1.0294019102496523\n",
      "232.62924194335938\n",
      "224.9853515625\n",
      "1.033975058054995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 2 texts, 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232.887939453125\n",
      "227.34487915039062\n",
      "1.024381724908207\n",
      "233.5050506591797\n",
      "228.46070861816406\n",
      "1.02207969182765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 3.0ms preprocess, 131.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237.13833618164062\n",
      "230.052978515625\n",
      "1.0307988086558697\n",
      "236.90219116210938\n",
      "233.42361450195312\n",
      "1.0149024196526917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237.37872314453125\n",
      "231.43063354492188\n",
      "1.0257013927175498\n",
      "231.7353057861328\n",
      "224.9652862548828\n",
      "1.0300936186375869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 129.1ms\n",
      "Speed: 4.0ms preprocess, 129.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228.25341796875\n",
      "221.21835327148438\n",
      "1.031801451340848\n",
      "224.39794921875\n",
      "219.07022094726562\n",
      "1.0243197283886742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 2 texts, 131.0ms\n",
      "Speed: 4.0ms preprocess, 131.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.0ms\n",
      "Speed: 4.0ms preprocess, 130.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218.83895874023438\n",
      "212.85791015625\n",
      "1.0280987846756267\n",
      "220.8407440185547\n",
      "213.8668975830078\n",
      "1.03260834899819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 1 text, 129.0ms\n",
      "Speed: 4.0ms preprocess, 129.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 132.0ms\n",
      "Speed: 3.0ms preprocess, 132.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.7318572998047\n",
      "213.66041564941406\n",
      "1.0330966390236451\n",
      "222.3909454345703\n",
      "215.1503448486328\n",
      "1.0336536787381474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 384x480 1 h_l, 1 logo, 2 texts, 130.0ms\n",
      "Speed: 3.0ms preprocess, 130.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n",
      "0: 384x480 1 h_l, 1 logo, 1 text, 130.1ms\n",
      "Speed: 4.0ms preprocess, 130.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 480)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained model\n",
    "model = YOLO('../model_versions/bestV2.pt')\n",
    "\n",
    "# Capture video from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "# List to store the ratios of ratio_lh_th\n",
    "ratios0 = []\n",
    "\n",
    "ratios1 = []\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLOv8 inference\n",
    "    results = model(frame)\n",
    "        # Move results to CPU and convert to numpy\n",
    "    boxes = results[0].boxes.cpu().numpy()\n",
    "    x1H_l, y1H_l, x2H_l, y2H_l = None, None, None, None\n",
    "    x1logo, y1logo, x2logo, y2logo = None, None, None, None\n",
    "    x1text, y1text, x2text, y2text = None, None, None, None\n",
    "    for box in boxes:\n",
    "        xyxy = box.xyxy[0]\n",
    "       \n",
    "        cls = int(box.cls[0])\n",
    "        conf = float(box.conf[0])\n",
    "        if(cls==0):\n",
    "             x1H_l, y1H_l, x2H_l, y2H_l = map(float, xyxy)\n",
    "        if(cls==1):\n",
    "             x1logo, y1logo, x2logo, y2logo = map(float, xyxy)\n",
    "        if(cls == 2 ):\n",
    "            x1text, y1text, x2text, y2text = map(float, xyxy)\n",
    "    \n",
    "    \n",
    "    if x1H_l is not None and x2H_l is not None  and x1logo is not None and x1H_l is not None and x1text is not None:\n",
    "        Xdis_between_logo_and_h_l = x1logo - x1H_l\n",
    "        Xdis_between_text_and_h_l = x1text - x1H_l\n",
    "        print(Xdis_between_logo_and_h_l)\n",
    "        print(Xdis_between_text_and_h_l)\n",
    "        ratio_lh_th = Xdis_between_logo_and_h_l/Xdis_between_text_and_h_l\n",
    "        print(ratio_lh_th)\n",
    "        ratios0.append(ratio_lh_th)\n",
    "        l_hLength = x2H_l-x1H_l\n",
    "        ratio_lh_lo = Xdis_between_logo_and_h_l/l_hLength\n",
    "        ratios1.append(ratio_lh_lo)\n",
    "    else:\n",
    "        print(\"Values are not available\")\n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "    # Display the results\n",
    "    cv2.imshow('YOLOv8 Inference', results[0].plot())\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "       \n",
    "    #print(\"x1: \", x1, \"y1: \", y1, \"x2: \", x2, \"y2: \", y2, \"cls: \", cls, \"conf: \", conf)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "if ratios0 and ratios1:\n",
    "    min_ratio0 = min(ratios0)\n",
    "    max_ratio0 = max(ratios0)\n",
    "    print(f\"Min ratio: {min_ratio0}\")\n",
    "    print(f\"Max ratio: {max_ratio0}\")\n",
    "    min_ratio1 = min(ratios1)\n",
    "    max_ratio1 = max(ratios1)\n",
    "    print(f\"Min ratio: {min_ratio1}\")\n",
    "    print(f\"Max ratio: {max_ratio1}\")\n",
    "else:\n",
    "    print(\"No ratios calculated.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9ca2d2",
   "metadata": {},
   "source": [
    "# notes\n",
    "\n",
    "### For the first logo:\n",
    "\n",
    "##### Ratio btween the distance of the h_l-logo and h_l-text:\\n\n",
    "-Min ratio: 0.9948937925977913\n",
    "-Max ratio: 1.018214823786773\n",
    "##### Ratio btween the distance of the h_l-logo and length of h_l:\\n\n",
    "-Min ratio: 1.1300224968018955\n",
    "-Max ratio: 1.2198453193438283"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
